{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e56bc13-55ae-4c2a-b47a-10f6db675732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "cat_names = ['Side', 'Country', 'Timezone', 'Amenity', 'Bump', 'Crossing', \n",
    "             'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', \n",
    "             'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', \n",
    "             'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af10ca8-bb45-4046-b619-48dd45ff301d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, split, explode, array_distinct, when, lower, lit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd5a2b1-33aa-4c8b-a074-2f6bec7277e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_file_path = \"/Volumes/mlops_dev/corretco/data/US_Accidents_March23_short.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bdfa62a-4d49-4e92-a810-009a810ab5ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_df = spark.read. \\\n",
    "    format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"separator\", \",\") \\\n",
    "    .load(data_file_path)\n",
    "\n",
    "raw_df.createOrReplaceTempView(\"raw_accidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c17d6b33-d37d-41c5-ab50-094da3c94ec0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Useless Features\n",
    "\n",
    "Features 'ID' doesn't provide any useful information about accidents themselves. 'TMC', 'Distance(mi)', 'End_Time' (we have start time), 'Duration', 'End_Lat', and 'End_Lng'(we have start location) can be collected only after the accident has already happened and hence cannot be predictors for serious accident prediction. For 'Description', the POI features have already been extracted from it by dataset creators. Let's get rid of these features first. 'Country' and 'Turning_Loop' dropped toom for they have only one class. More than 60% percent of 'Number', 'Wind_Chill(F)' is missing; we drop these columns too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "337c412d-80a9-4e63-991a-fe8d67369c85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# We arbitrarily choose one source only. Different websites / databases use different collection and classification methodologies. We will focus on the source offering the most data: Source1\n",
    "\n",
    "clean_df = spark.sql(\"\"\"\n",
    "    WITH median_precipitation AS (\n",
    "      SELECT median(CAST(`Precipitation(in)` as decimal(12,4))) AS median_precip\n",
    "      FROM raw_accidents\n",
    "      WHERE `Precipitation(in)` IS NOT NULL\n",
    "    )\n",
    "    SELECT\n",
    "        CAST(`Severity` as string) as `Severity`,\n",
    "        CAST(`Start_Time` as timestamp) as `Start_Time`,\n",
    "        CAST(extract(YEAR FROM CAST(`Start_Time` as timestamp)) as int) as `Year`,\n",
    "        CAST(extract(MONTH FROM CAST(`Start_Time` as timestamp)) as int) as `Month`,\n",
    "        CAST(WEEKDAY(CAST(`Start_Time` as timestamp)) as int) as `Weekday`,\n",
    "        CAST(extract(DAY FROM CAST(`Start_Time` as timestamp)) as int) as `Day`,\n",
    "        CAST(extract(HOUR FROM CAST(`Start_Time` as timestamp)) as int) as `Hour`,\n",
    "        CAST(extract(MINUTE FROM CAST(`Start_Time` as timestamp)) as int) as `Minute`, \n",
    "        CAST(`Start_Lat` as decimal(38, 10)) as `Start_Lat`,\n",
    "        CAST(`Start_Lng` as decimal(38, 10)) as `Start_Lng`,\n",
    "        CAST(`Street` as string) as `Street`,\n",
    "        CAST(`City` as string) as `City`,\n",
    "        CAST(`County` as string) as `County`,\n",
    "        CAST(`State` as string) as `State`,\n",
    "        CAST(`Zipcode` as string) as `Zipcode`,\n",
    "        CAST(`Timezone` as string) as `Timezone`,\n",
    "        CAST(`Airport_Code` as string) as `Airport_Code`,\n",
    "        CAST(`Weather_Timestamp` as timestamp) as `Weather_Timestamp`,\n",
    "        CAST(`Temperature(F)` as decimal(38, 10)) as `Temperature(F)`,\n",
    "        CAST(`Humidity(%)` as decimal(38, 10)) as `Humidity(%)`,\n",
    "        CAST(`Pressure(in)` as decimal(38, 10)) as `Pressure(in)`,\n",
    "        CAST(`Visibility(mi)` as decimal(38, 10)) as `Visibility(mi)`,\n",
    "        CASE\n",
    "          WHEN Wind_Direction = 'Calm' THEN 'CALM'\n",
    "          WHEN Wind_Direction = 'West' THEN 'W'\n",
    "          WHEN Wind_Direction = 'WSW' THEN 'W'\n",
    "          WHEN Wind_Direction = 'South' THEN 'S'\n",
    "          WHEN Wind_Direction = 'SSW' THEN 'S'\n",
    "          WHEN Wind_Direction = 'North' THEN 'N'\n",
    "          WHEN Wind_Direction = 'NNW' THEN 'N'\n",
    "          WHEN Wind_Direction = 'East' THEN 'E'\n",
    "          WHEN Wind_Direction = 'ESE' THEN 'E'\n",
    "          WHEN Wind_Direction = 'Variable' THEN 'VAR'\n",
    "          ELSE Wind_Direction\n",
    "        END as `Wind_Direction`,\n",
    "        CAST(`Wind_Speed(mph)` as decimal(38, 10)) as `Wind_Speed(mph)`,\n",
    "        CASE\n",
    "          WHEN `Precipitation(in)` IS NULL THEN (SELECT median_precip FROM median_precipitation)\n",
    "          ELSE CAST(`Precipitation(in)` as decimal(38, 10))\n",
    "        END as `Precipitation(in)`,\n",
    "        CAST(`Weather_Condition` as string) as `Weather_Condition`,\n",
    "        CAST(`Amenity` as boolean) as `Amenity`,\n",
    "        CAST(`Bump` as boolean) as `Bump`,\n",
    "        CAST(`Crossing` as boolean) as `Crossing`,\n",
    "        CAST(`Give_Way` as boolean) as `Give_Way`,\n",
    "        CAST(`Junction` as boolean) as `Junction`,\n",
    "        CAST(`No_Exit` as boolean) as `No_Exit`,\n",
    "        CAST(`Railway` as boolean) as `Railway`,\n",
    "        CAST(`Roundabout` as boolean) as `Roundabout`,\n",
    "        CAST(`Station` as boolean) as `Station`,\n",
    "        CAST(`Stop` as boolean) as `Stop`,\n",
    "        CAST(`Traffic_Calming` as boolean) as `Traffic_Calming`,\n",
    "        CAST(`Traffic_Signal` as boolean) as `Traffic_Signal`,\n",
    "        CAST(`Sunrise_Sunset` as string) as `Sunrise_Sunset`,\n",
    "        CAST(`Civil_Twilight` as string) as `Civil_Twilight`,\n",
    "        CAST(`Nautical_Twilight` as string) as `Nautical_Twilight`,\n",
    "        CAST(`Astronomical_Twilight` as string) as `Astronomical_Twilight`\n",
    "    FROM raw_accidents\n",
    "    WHERE Source = 'Source1'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa18d00-7161-4274-bdaf-c505ea75acd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Special treatment of weather conditions\n",
    "\n",
    "# We first simplify the weather conditions to a few categories\n",
    "clean_df = clean_df.withColumn('Clear', when(lower(col('Weather_Condition')).contains('clear'), True).otherwise(False))\n",
    "clean_df = clean_df.withColumn('Cloud', when(lower(col('Weather_Condition')).contains('cloud') | lower(col('Weather_Condition')).contains('overcast'), True).otherwise(False))\n",
    "clean_df = clean_df.withColumn('Rain', when(lower(col('Weather_Condition')).contains('rain') | lower(col('Weather_Condition')).contains('storm'), True).otherwise(False))\n",
    "clean_df = clean_df.withColumn('Heavy_Rain', when(lower(col('Weather_Condition')).contains('heavy rain') |\n",
    "                                       lower(col('Weather_Condition')).contains('rain shower') |\n",
    "                                       lower(col('Weather_Condition')).contains('heavy t-storm') |\n",
    "                                       lower(col('Weather_Condition')).contains('heavy thunderstorms'), True).otherwise(False))\n",
    "clean_df = clean_df.withColumn('Snow', when(lower(col('Weather_Condition')).contains('snow') |\n",
    "                                 lower(col('Weather_Condition')).contains('sleet') |\n",
    "                                 lower(col('Weather_Condition')).contains('ice'), True).otherwise(False))\n",
    "clean_df = clean_df.withColumn('Heavy_Snow', when(lower(col('Weather_Condition')).contains('heavy snow') |\n",
    "                                       lower(col('Weather_Condition')).contains('heavy sleet') |\n",
    "                                       lower(col('Weather_Condition')).contains('heavy ice pellets') |\n",
    "                                       lower(col('Weather_Condition')).contains('snow showers') |\n",
    "                                       lower(col('Weather_Condition')).contains('squalls'), True).otherwise(False))\n",
    "clean_df = clean_df.withColumn('Fog', when(lower(col('Weather_Condition')).contains('fog'), True).otherwise(False))\n",
    "\n",
    "# Show weather conditions as NULLs if the Weather_Condition is NULL\n",
    "weather = ['Clear', 'Cloud', 'Rain', 'Heavy_Rain', 'Snow', 'Heavy_Snow', 'Fog']\n",
    "for condition in weather:\n",
    "    clean_df = clean_df.withColumn(condition,\n",
    "                       when(col('Weather_Condition').isNull(), lit(None))\n",
    "                       .otherwise(col(condition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "417887cc-3c21-4448-890a-2a7d8c3faeb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows with null values in the specified columns\n",
    "clean_df = clean_df.dropna(subset=['City', 'Zipcode', 'Airport_Code',\n",
    "                       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca464e4b-72b3-41c3-bd4c-d1d450766388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(clean_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "base_preprocessing_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
